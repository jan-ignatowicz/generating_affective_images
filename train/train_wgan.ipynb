{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import grad\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import metrics as mt\n",
    "import settings as opt\n",
    "import weights\n",
    "from preprocess.dataset import ValenceArousalWithClassesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "# Choose model and dataset\n",
    "\n",
    "# Select dataset to train on - possible choices: affective, augmented_affective, cifar10\n",
    "dataset_choice = \"affective\"\n",
    "\n",
    "# Select model to train on - WGAN, WGAN_D, WGAN_SN\n",
    "model_choice = \"WGAN\"\n",
    "\n",
    "import model.wgan as gan"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gen_imgs_path = opt.outi + model_choice + '/' + dataset_choice + '/'\n",
    "save_model_checkpoints = opt.outc + model_choice + '/' + dataset_choice + '/'\n",
    "\n",
    "# create directories for output\n",
    "try:\n",
    "    os.makedirs(gen_imgs_path)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.makedirs(save_model_checkpoints)\n",
    "except OSError:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Image preprocessing\n",
    "pre_process = transforms.Compose([\n",
    "    transforms.Resize(opt.image_size),\n",
    "    transforms.CenterCrop(opt.image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "if dataset_choice == \"cifar10\":\n",
    "    dataset = dset.CIFAR10(\n",
    "        root=\"../data/cifar10\",\n",
    "        download=True,\n",
    "        transform=pre_process\n",
    "    )\n",
    "    n_classes = 10\n",
    "elif dataset_choice == \"affective\":\n",
    "    dataset = ValenceArousalWithClassesDataset(csv_file=opt.annonations_file,\n",
    "                                               root_dir=opt.all_images_path,\n",
    "                                               transform=pre_process)\n",
    "    n_classes = 13\n",
    "else:\n",
    "    dataset = ValenceArousalWithClassesDataset(csv_file=opt.augmented_annonations_file,\n",
    "                                               root_dir=opt.augmented_images_path,\n",
    "                                               transform=pre_process)\n",
    "    n_classes = 13\n",
    "\n",
    "# Create the dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=opt.batch_size, shuffle=True, num_workers=4,\n",
    "                        drop_last=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def gradient_penalty(x, y, f):\n",
    "    # interpolation\n",
    "    shape = [x.size(0)] + [1] * (x.dim() - 1)\n",
    "    alpha = torch.rand(shape).to(device)\n",
    "    z = x + alpha * (y - x)\n",
    "\n",
    "    # gradient penalty\n",
    "    z = Variable(z, requires_grad=True).to(device)\n",
    "    o = f(z)\n",
    "    g = grad(o, z, grad_outputs=torch.ones(o.size()).to(device), create_graph=True)[0].view(\n",
    "        z.size(0), -1)\n",
    "    gp = ((g.norm(p=2, dim=1) - 1) ** 2).mean()\n",
    "\n",
    "    return gp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the GAN model\n",
    "\n",
    "# Create or load the generator\n",
    "generator = gan.Generator(opt.latent_dim, opt.num_channels, opt.ngf, opt.n_classes).to(device)\n",
    "generator.apply(weights.weights_init)\n",
    "\n",
    "# Create or load the discriminator\n",
    "if model_choice == \"WGAN\":\n",
    "    discriminator = gan.Discriminator(opt.num_channels, opt.ndf, opt.n_classes).to(device)\n",
    "elif model_choice == \"WGAN_D\":\n",
    "    discriminator = gan.DiscriminatorDropout(opt.num_channels, opt.ndf, opt.n_classes).to(device)\n",
    "else:\n",
    "    discriminator = gan.DiscriminatorSN(opt.num_channels, opt.ndf, opt.n_classes).to(device)\n",
    "\n",
    "discriminator.apply(weights.weights_init)\n",
    "\n",
    "# Loss functions\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "# with condition GAN, these fields are unnecessary\n",
    "real_label = 0.9  # GAN trick, real examples are real in 90%\n",
    "fake_label = 0.\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(discriminator.parameters(), lr=opt.lr_D, betas=(opt.beta1, opt.beta2))\n",
    "optimizerG = optim.Adam(generator.parameters(), lr=opt.lr_G, betas=(opt.beta1, opt.beta2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "z_sample = Variable(torch.randn(100, opt.latent_dim))\n",
    "z_sample = z_sample.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "fid_score_history = []\n",
    "kid_score_history = []\n",
    "\n",
    "fake_images_list = []\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(opt.epochs):\n",
    "\n",
    "    ##############################\n",
    "    ### COMPUTE METRICS\n",
    "    if epoch % 5 == 0:\n",
    "        print(\"Global step: {}. Computing metrics...\".format(global_step))\n",
    "\n",
    "        # get random real samples\n",
    "        samples = random.sample(range(len(dataset)), opt.fid_batch)\n",
    "        real_samples = [dataset[s][0] for s in samples]\n",
    "        real_samples = torch.stack(real_samples, dim=0).to(device)\n",
    "\n",
    "        # generate random fake samples\n",
    "        fake_samples = []\n",
    "\n",
    "        noise = Variable(\n",
    "            torch.FloatTensor(np.random.normal(0, 1, (opt.fid_batch, opt.latent_dim)))).to(\n",
    "            device)\n",
    "        gen_labels = Variable(\n",
    "            torch.LongTensor(np.random.randint(0, n_classes, opt.fid_batch))).to(device)\n",
    "\n",
    "        for k in tqdm(range(opt.fid_batch), desc=\"Generating fake images\"):\n",
    "            noise_ = noise[k * opt.batch_size: (k + 1) * opt.batch_size]\n",
    "            gen_labels_ = gen_labels[k * opt.batch_size: (k + 1) * opt.batch_size]\n",
    "\n",
    "            fake_samples.append(generator(noise_, gen_labels_))\n",
    "        fake_samples = torch.cat(fake_samples, dim=0).to(device)\n",
    "\n",
    "        print(\"Computing KID and FID...\")\n",
    "        kid, fid = mt.compute_metrics(real_samples, fake_samples)\n",
    "\n",
    "        print(\"FID: {:.4f}\".format(fid))\n",
    "\n",
    "        print(\"KID: {:.4f}\".format(kid))\n",
    "\n",
    "        fid_score_history.append(fid)\n",
    "        kid_score_history.append(kid)\n",
    "\n",
    "    ##############################\n",
    "\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        # step\n",
    "        step = epoch * len(dataloader) + i + 1\n",
    "\n",
    "        # set train\n",
    "        generator.train()\n",
    "\n",
    "        # leafs\n",
    "        imgs = Variable(imgs).to(device)\n",
    "        bs = imgs.size(0)\n",
    "        z = Variable(torch.randn(bs, opt.latent_dim)).to(device)\n",
    "\n",
    "        f_imgs = generator(z)\n",
    "\n",
    "        # train D\n",
    "        r_logit = discriminator(imgs)\n",
    "        f_logit = discriminator(f_imgs.detach())\n",
    "\n",
    "        wd = r_logit.mean() - f_logit.mean()  # Wasserstein-1 Distance\n",
    "        gp = gradient_penalty(imgs.data, f_imgs.data, discriminator)\n",
    "        d_loss = -wd + gp * 10.0\n",
    "\n",
    "        discriminator.zero_grad()\n",
    "        d_loss.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        # train G\n",
    "        z = Variable(torch.randn(bs, opt.latent_dim)).to(device)\n",
    "        f_imgs = generator(z)\n",
    "        f_logit = discriminator(f_imgs)\n",
    "        g_loss = -f_logit.mean()\n",
    "\n",
    "        discriminator.zero_grad()\n",
    "        generator.zero_grad()\n",
    "        g_loss.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(g_loss.item())\n",
    "        D_losses.append(d_loss.item())\n",
    "\n",
    "        global_step += 1\n",
    "\n",
    "        # Output training stats\n",
    "        if i % opt.log_interval == 0:\n",
    "            print(\n",
    "                \"[{}/{}][{}/{}] Loss_D: {:.4f} Loss_G: {:.4f}\".format(\n",
    "                    epoch,\n",
    "                    opt.epochs,\n",
    "                    i,\n",
    "                    len(dataloader),\n",
    "                    d_loss.item(),\n",
    "                    g_loss.item()\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Save generated images after each epoch\n",
    "    noise = Variable(torch.FloatTensor(np.random.normal(0, 1, (64, opt.latent_dim)))).to(device)\n",
    "    gen_labels = Variable(torch.LongTensor(np.random.randint(0, n_classes, 64))).to(device)\n",
    "\n",
    "    fake_images = generator(noise).detach().cpu()\n",
    "\n",
    "    vutils.save_image(fake_images,\n",
    "                      \"%s/fake_%s_epoch_%03d.png\" % (gen_imgs_path, dataset_choice, epoch),\n",
    "                      normalize=True)\n",
    "\n",
    "    # Save generator and discriminator weights after each 20 epochs\n",
    "    if epoch % 20 == 0:\n",
    "        torch.save(generator.state_dict(),\n",
    "                   \"%s/netG_%s_epoch_%d.pth\" % (save_model_checkpoints, dataset_choice, epoch))\n",
    "        torch.save(discriminator.state_dict(),\n",
    "                   \"%s/netD_%s_epoch_%d.pth\" % (save_model_checkpoints, dataset_choice, epoch))\n",
    "\n",
    "print(\"Training is finished!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Generator and Discriminator loss during training\")\n",
    "plt.plot(G_losses, label=\"Generator\")\n",
    "plt.plot(D_losses, label=\"Discriminator\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# FID results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"FID score\")\n",
    "plt.plot(fid_score_history)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"FID value\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# KID results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"KID score\")\n",
    "plt.plot(kid_score_history)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"KID value\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(fid_score_history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(kid_score_history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(G_losses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(D_losses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}