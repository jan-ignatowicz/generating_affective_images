{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import metrics as mt\n",
    "import settings as opt\n",
    "import weights\n",
    "from preprocess.dataset import ValenceArousalWithClassesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "# Choose model and dataset\n",
    "\n",
    "# Select dataset to train on - possible choices: affective, augmented_affective, cifar10\n",
    "dataset_choice = \"affective\"\n",
    "\n",
    "# Select model to train on - ACGAN, ACGAN_D, ACGAN_SN\n",
    "model_choice = \"ACGAN\"\n",
    "\n",
    "import model.acgan as gan"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gen_imgs_path = opt.outi + model_choice + '/' + dataset_choice + '/'\n",
    "save_model_checkpoints = opt.outc + model_choice + '/' + dataset_choice + '/'\n",
    "\n",
    "# create directories for output\n",
    "try:\n",
    "    os.makedirs(gen_imgs_path)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.makedirs(save_model_checkpoints)\n",
    "except OSError:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Image preprocessing\n",
    "pre_process = transforms.Compose([\n",
    "    transforms.Resize(opt.image_size),\n",
    "    transforms.CenterCrop(opt.image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "if dataset_choice == \"cifar10\":\n",
    "    dataset = dset.CIFAR10(\n",
    "        root=\"../data/cifar10\",\n",
    "        download=True,\n",
    "        transform=pre_process\n",
    "    )\n",
    "    n_classes = 10\n",
    "elif dataset_choice == \"affective\":\n",
    "    dataset = ValenceArousalWithClassesDataset(csv_file=opt.annonations_file,\n",
    "                                               root_dir=opt.all_images_path,\n",
    "                                               transform=pre_process)\n",
    "    n_classes = 13\n",
    "else:\n",
    "    dataset = ValenceArousalWithClassesDataset(csv_file=opt.augmented_annonations_file,\n",
    "                                               root_dir=opt.augmented_images_path,\n",
    "                                               transform=pre_process)\n",
    "    n_classes = 13\n",
    "\n",
    "# Create the dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=opt.batch_size, shuffle=True, num_workers=4,\n",
    "                        drop_last=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Method for storing generated images\n",
    "def generate_imgs(generator, epoch):\n",
    "    fixed_z = torch.randn(1, n_classes, opt.latent_dim)\n",
    "    fixed_z = torch.repeat_interleave(fixed_z, 10, 0).reshape(-1, opt.latent_dim).to(device)\n",
    "    fixed_label = torch.arange(0, n_classes)\n",
    "    fixed_label = torch.repeat_interleave(fixed_label, 10).to(device)\n",
    "\n",
    "    generator.eval()\n",
    "    fake_imgs = generator(fixed_z, fixed_label)\n",
    "    fake_imgs_ = vutils.make_grid(fake_imgs.to(device)[:n_classes * 10], padding=2, normalize=True,\n",
    "                                  nrow=n_classes).cpu()\n",
    "\n",
    "    vutils.save_image(fake_imgs_, os.path.join(gen_imgs_path, 'sample_' + str(epoch) + '.png'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the GAN model\n",
    "generator = gan.Generator(latent_dim=opt.latent_dim, num_classes=n_classes,\n",
    "                          num_channels=opt.num_channels)\n",
    "generator.apply(weights.weights_init)\n",
    "\n",
    "if model_choice == \"ACGAN\":\n",
    "    discriminator = gan.Discriminator(num_channels=opt.num_channels, n_classes=n_classes)\n",
    "elif model_choice == \"ACGAN_D\":\n",
    "    discriminator = gan.DiscriminatorDropout(num_channels=opt.num_channels, n_classes=n_classes)\n",
    "else:\n",
    "    discriminator = gan.DiscriminatorSN(num_channels=opt.num_channels, n_classes=n_classes)\n",
    "\n",
    "discriminator.apply(weights.weights_init)\n",
    "\n",
    "# Loss functions\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(discriminator.parameters(), lr=opt.lr_D, betas=(opt.beta1, opt.beta2))\n",
    "optimizerG = optim.Adam(generator.parameters(), lr=opt.lr_G, betas=(opt.beta1, opt.beta2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fix images for viz\n",
    "fixed_z = torch.randn(1, n_classes, opt.latent_dim)\n",
    "fixed_z = torch.repeat_interleave(fixed_z, 10, 0).reshape(-1, opt.latent_dim)\n",
    "fixed_label = torch.arange(0, n_classes)\n",
    "fixed_label = torch.repeat_interleave(fixed_label, 10)\n",
    "\n",
    "# Labels\n",
    "real_label = torch.ones(opt.batch_size)\n",
    "fake_label = torch.zeros(opt.batch_size)\n",
    "\n",
    "# GPU Compatibility\n",
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    generator, discriminator = generator.cuda(), discriminator.cuda()\n",
    "    real_label, fake_label = real_label.cuda(), fake_label.cuda()\n",
    "    fixed_z, fixed_label = fixed_z.cuda(), fixed_label.cuda()\n",
    "\n",
    "total_iters = 0\n",
    "max_iter = len(dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "fid_score_history = []\n",
    "kid_score_history = []\n",
    "\n",
    "fake_images_list = []\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(opt.epochs):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    ##############################\n",
    "    ### COMPUTE METRICS\n",
    "    if epoch % 5 == 0:\n",
    "        print(\"Global step: {}. Computing metrics...\".format(global_step))\n",
    "\n",
    "        # get random real samples\n",
    "        samples = random.sample(range(len(dataset)), 192)\n",
    "        real_samples = [dataset[s][0] for s in samples]\n",
    "        real_samples = torch.stack(real_samples, dim=0).to(device)\n",
    "\n",
    "        # generate random fake samples\n",
    "        fake_samples = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(192, opt.latent_dim) * 2 - 1\n",
    "            z.to(device)\n",
    "            # z = torch.rand(192, opt.latent_dim, device=device) * 2 - 1\n",
    "            gen_labels = Variable(\n",
    "                torch.LongTensor(np.random.randint(0, n_classes, 192))).to(device)\n",
    "\n",
    "            for k in tqdm(range(192 // opt.batch_size), desc=\"Generating fake images\"):\n",
    "                z_ = z[k * opt.batch_size: (k + 1) * opt.batch_size].to(device)\n",
    "                gen_labels_ = gen_labels[k * opt.batch_size: (k + 1) * opt.batch_size].to(device)\n",
    "\n",
    "                fake_samples.append(generator(z_, gen_labels_))\n",
    "\n",
    "            fake_samples = torch.cat(fake_samples, dim=0).to(device)\n",
    "\n",
    "        print(\"Computing KID and FID...\")\n",
    "        kid, fid = mt.compute_metrics(real_samples, fake_samples)\n",
    "\n",
    "        print(\"FID: {:.4f}\".format(fid))\n",
    "\n",
    "        print(\"KID: {:.4f}\".format(kid))\n",
    "\n",
    "        fid_score_history.append(fid)\n",
    "        kid_score_history.append(kid)\n",
    "\n",
    "    ##############################\n",
    "\n",
    "    for i, data in enumerate(dataloader):\n",
    "\n",
    "        total_iters += 1\n",
    "\n",
    "        # Format batch\n",
    "        x_real = data[0].to(device)\n",
    "        x_label = data[1].to(device)  # Without condition in GAN, this is unnecessary\n",
    "\n",
    "        batch_size = x_real.size(0)\n",
    "        # Loading data\n",
    "        # x_real, x_label = data\n",
    "\n",
    "        z_fake = torch.randn(batch_size, opt.latent_dim)\n",
    "\n",
    "        if is_cuda:\n",
    "            x_real = x_real.cuda()\n",
    "            x_label = x_label.cuda()\n",
    "            z_fake = z_fake.cuda()\n",
    "\n",
    "        # Generate fake data\n",
    "        x_fake = generator(z_fake, x_label)\n",
    "\n",
    "        # Train Discriminator\n",
    "        fake_out = discriminator(x_fake.detach(), x_label)\n",
    "        real_out = discriminator(x_real.detach(), x_label)\n",
    "\n",
    "        d_loss = (adversarial_loss(fake_out, fake_label) + adversarial_loss(real_out,\n",
    "                                                                            real_label)) / 2\n",
    "\n",
    "        optimizerD.zero_grad()\n",
    "        d_loss.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Train Generator\n",
    "        fake_out = discriminator(x_fake, x_label)\n",
    "        g_loss = adversarial_loss(fake_out, real_label)\n",
    "\n",
    "        optimizerG.zero_grad()\n",
    "        g_loss.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(g_loss.item())\n",
    "        D_losses.append(d_loss.item())\n",
    "\n",
    "        global_step += 1\n",
    "\n",
    "        # Output training stats\n",
    "        if i % opt.log_interval == 0:\n",
    "            print(\"Epoch: \" + str(epoch + 1) + \"/\" + str(opt.epochs)\n",
    "                  + \"\\titer: \" + str(i) + \"/\" + str(max_iter)\n",
    "                  + \"\\ttotal_iters: \" + str(total_iters)\n",
    "                  + \"\\td_loss:\" + str(round(d_loss.item(), 4))\n",
    "                  + \"\\tg_loss:\" + str(round(g_loss.item(), 4))\n",
    "                  )\n",
    "\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        generate_imgs(generator, epoch)\n",
    "\n",
    "    # Save generator and discriminator weights after each 20 epochs\n",
    "    if epoch % 20 == 0:\n",
    "        torch.save(generator.state_dict(),\n",
    "                   \"%s/netG_%s_epoch_%d.pth\" % (save_model_checkpoints, dataset_choice, epoch))\n",
    "        torch.save(discriminator.state_dict(),\n",
    "                   \"%s/netD_%s_epoch_%d.pth\" % (save_model_checkpoints, dataset_choice, epoch))\n",
    "\n",
    "print(\"Training is finished!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Generator and Discriminator loss during training\")\n",
    "plt.plot(G_losses, label=\"Generator\")\n",
    "plt.plot(D_losses, label=\"Discriminator\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# FID results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"FID score\")\n",
    "plt.plot(fid_score_history)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"FID value\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# KID results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"KID score\")\n",
    "plt.plot(kid_score_history)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"KID value\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(fid_score_history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(kid_score_history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(G_losses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(D_losses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}